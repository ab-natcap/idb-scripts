{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "active-greeting",
   "metadata": {},
   "source": [
    "# Accuracy Assessment Stats and Confusion Matrices for Sargassum Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "novel-baghdad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "import sklearn.metrics as skmetrics\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "legitimate-auction",
   "metadata": {},
   "source": [
    "## Load the AA shapefiles into GeodataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dangerous-regulation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Validated Accuracy Assessment Shapefile\n",
    "source_dir = r'/Users/arbailey/Google Drive/My Drive/sargassum/aa'\n",
    "   \n",
    "# Use already existing files merged across all dates\n",
    "file = 'aaPoints_validated_2019.shp'\n",
    "sargassum_aa_gdf = gpd.read_file(os.path.join(source_dir,file))      \n",
    "sargassum_aa_gdf = sargassum_aa_gdf.dropna()  # remove rows w/null\n",
    "print(sargassum_aa_gdf.describe())\n",
    "sargassum_aa_gdf = sargassum_aa_gdf.astype({\"validclass\": int, \"validpa\": int})\n",
    "print(sargassum_aa_gdf.dtypes)\n",
    "sargassum_aa_gdf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "headed-choir",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Original SR AA Patches\n",
    "sr_patch_gdf = gpd.read_file(os.path.join(source_dir,'aaPatches_2019.shp'))\n",
    "# TOA AA Patches -- 3 versions\n",
    "toa1_patch_gdf = gpd.read_file(os.path.join(source_dir,'aaPatches_2019toa.shp'))\n",
    "toa2_patch_gdf = gpd.read_file(os.path.join(source_dir,'aaPatches_2019toa_v2.shp'))\n",
    "toa3_patch_gdf = gpd.read_file(os.path.join(source_dir,'aaPatches_2019toa_v3.shp'))\n",
    "\n",
    "print(sr_patch_gdf.dtypes)\n",
    "print(toa1_patch_gdf.dtypes)\n",
    "toa1_patch_gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "virtual-capacity",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join samples with patch IDs to validated AA points\n",
    "def combine_aa_patch(aa_gdf, patch_gdf, src):\n",
    "    combo_gdf = pd.merge(aa_gdf, patch_gdf.drop(columns=['geometry']), on=\"aa_id\", how=\"left\")\n",
    "    combo_gdf = combo_gdf.fillna(0)\n",
    "    if src.startswith('toa'):\n",
    "        combo_gdf = combo_gdf.drop(columns='sargassum')\n",
    "        combo_gdf = combo_gdf.rename(columns={'toa_patch':'patch', 'toa_sarg':'sargassum'})\n",
    "    combo_gdf = combo_gdf.astype({\"patch\": 'int64','sargassum':'int64'})\n",
    "    combo_gdf['Date']= pd.to_datetime(combo_gdf['imagedate'])\n",
    "    combo_gdf['source'] = src\n",
    "    return combo_gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "parliamentary-coalition",
   "metadata": {},
   "outputs": [],
   "source": [
    "sr_combo_gdf = combine_aa_patch(sargassum_aa_gdf, sr_patch_gdf, 'sr1') \n",
    "sr_combo_gdf  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "straight-modern",
   "metadata": {},
   "outputs": [],
   "source": [
    "toa1_combo_gdf = combine_aa_patch(sargassum_aa_gdf, toa1_patch_gdf, 'toa1')\n",
    "toa1_combo_gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "after-modem",
   "metadata": {},
   "outputs": [],
   "source": [
    "toa2_combo_gdf = combine_aa_patch(sargassum_aa_gdf, toa2_patch_gdf, 'toa2')\n",
    "toa2_combo_gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stupid-conference",
   "metadata": {},
   "outputs": [],
   "source": [
    "toa3_combo_gdf = combine_aa_patch(sargassum_aa_gdf, toa3_patch_gdf, 'toa3')\n",
    "toa3_combo_gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interim-ottawa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combo_gdf = pd.concat([sr_combo_gdf, toa1_combo_gdf, toa2_combo_gdf, toa3_combo_gdf])\n",
    "# combo_gdf['Date']= pd.to_datetime(combo_gdf['imagedate'])\n",
    "# combo_gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "placed-stick",
   "metadata": {},
   "outputs": [],
   "source": [
    "def aa_metrics(df):\n",
    "    y_true = df['validpa']\n",
    "    y_pred = df['sargassum']\n",
    "    date_min = df['imagedate'].min()\n",
    "    date_max = df['imagedate'].max()\n",
    "    source = df['source'].iloc[0]\n",
    "    acc_score = accuracy_score(y_true, y_pred)\n",
    "    precision = skmetrics.precision_score(y_true, y_pred)\n",
    "    precision_weighted = skmetrics.precision_score(y_true, y_pred, average='weighted')\n",
    "    recall = skmetrics.recall_score(y_true, y_pred)\n",
    "    recall_weighted = skmetrics.recall_score(y_true, y_pred, average='weighted')\n",
    "    f1 = skmetrics.f1_score(y_true, y_pred)\n",
    "    f1_weighted = skmetrics.f1_score(y_true, y_pred, average='weighted')\n",
    "    support = skmetrics.precision_recall_fscore_support(y_true, y_pred)[3][1]\n",
    "#     print(skmetrics.precision_recall_fscore_support(y_true, y_pred))\n",
    "    return [source,date_min, date_max, acc_score, precision, precision_weighted, recall, recall_weighted, f1, f1_weighted, support]\n",
    " \n",
    "print(aa_metrics(toa3_combo_gdf))\n",
    "print(toa3_combo_gdf.groupby(['imagedate']).apply(aa_metrics))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "different-checkout",
   "metadata": {},
   "outputs": [],
   "source": [
    "sr_metrics_all = aa_metrics(sr_combo_gdf)\n",
    "toa1_metrics_all = aa_metrics(toa1_combo_gdf)\n",
    "toa2_metrics_all = aa_metrics(toa2_combo_gdf)\n",
    "toa3_metrics_all = aa_metrics(toa3_combo_gdf)\n",
    "metrics_all = [sr_metrics_all, toa1_metrics_all, toa2_metrics_all, toa3_metrics_all]\n",
    "print(metrics_all)\n",
    "\n",
    "metrics_bydate = []\n",
    "sr_metrics_bydate = sr_combo_gdf.groupby(['imagedate']).apply(aa_metrics).tolist()\n",
    "toa1_metrics_bydate = toa1_combo_gdf.groupby(['imagedate']).apply(aa_metrics).tolist()\n",
    "toa2_metrics_bydate = toa2_combo_gdf.groupby(['imagedate']).apply(aa_metrics).tolist()\n",
    "toa3_metrics_bydate = toa3_combo_gdf.groupby(['imagedate']).apply(aa_metrics).tolist()\n",
    "metrics_bydate = []\n",
    "metrics_bydate.extend(sr_metrics_bydate)\n",
    "metrics_bydate.extend(toa1_metrics_bydate)\n",
    "metrics_bydate.extend(toa2_metrics_bydate)\n",
    "metrics_bydate.extend(toa3_metrics_bydate)\n",
    "\n",
    "print(metrics_bydate)\n",
    "print(len(metrics_bydate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "practical-shakespeare",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_bydate_df = pd.DataFrame(metrics_bydate, columns = ['source', 'date_min', 'date_max', 'acc_score', 'precision', 'precision_weighted', 'recall', 'recall_weighted', 'f1', 'f1_weighted', 'support']) \n",
    "metrics_bydate_df['Date']= pd.to_datetime(metrics_bydate_df['date_min'])\n",
    "metrics_bydate_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fifty-thickness",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme(style='darkgrid', palette='Set3', font='Arial', font_scale=1.2)\n",
    "\n",
    "# def acc_barchart(y='recall',ylabel='Recall'):\n",
    "#     f, ax = plt.subplots(figsize=(20, 10))\n",
    "    \n",
    "f, axs = plt.subplots(4, 2, figsize=(20, 20)) # , gridspec_kw=dict(width_ratios=[4, 3]))\n",
    "\n",
    "# Make the plots\n",
    "sns.barplot(data=metrics_bydate_df, x=\"date_min\", y=\"f1\", hue=\"source\", linewidth=0.5, ec='.6', ax=axs[0][0])\n",
    "sns.barplot(data=metrics_bydate_df, x=\"date_min\", y=\"f1_weighted\", hue=\"source\", linewidth=0.5, ec='.6', ax=axs[0][1])\n",
    "sns.barplot(data=metrics_bydate_df, x=\"date_min\", y=\"recall\", hue=\"source\", linewidth=0.5, ec='.6', ax=axs[1][0])\n",
    "sns.barplot(data=metrics_bydate_df, x=\"date_min\", y=\"recall_weighted\", hue=\"source\", linewidth=0.5, ec='.6', ax=axs[1][1])\n",
    "sns.barplot(data=metrics_bydate_df, x=\"date_min\", y=\"precision\", hue=\"source\", linewidth=0.5, ec='.6', ax=axs[2][0])\n",
    "sns.barplot(data=metrics_bydate_df, x=\"date_min\", y=\"precision_weighted\", hue=\"source\", linewidth=0.5, ec='.6', ax=axs[2][1])\n",
    "sns.barplot(data=metrics_bydate_df, x=\"date_min\", y=\"acc_score\", hue=\"source\", linewidth=0.5, ec='.6', ax=axs[3][0])\n",
    "sns.barplot(data=metrics_bydate_df[metrics_bydate_df.source == 'sr1'], x=\"date_min\", y=\"support\", color='#a6cee3',linewidth=0.5, ec='.6', ax=axs[3][1])\n",
    "# Clean up the Figure -- can't figure out how to do some of these things in loop, so just hacking it ehre\n",
    "axs[0][1].get_legend().remove()\n",
    "axs[1][0].get_legend().remove()\n",
    "axs[1][1].get_legend().remove()\n",
    "axs[2][0].get_legend().remove()\n",
    "axs[2][1].get_legend().remove()\n",
    "axs[3][0].get_legend().remove()\n",
    "# axs[3][1].get_legend().remove()\n",
    "\n",
    "axs[0][0].set(ylim=(0, 1), xlabel='', ylabel = 'F1', yticks=[0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1])\n",
    "axs[0][1].set(ylim=(0, 1), xlabel='', ylabel = 'Weighted F1', yticks=[0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1])\n",
    "axs[1][0].set(ylim=(0, 1), xlabel='', ylabel = 'Recall', yticks=[0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1])\n",
    "axs[1][1].set(ylim=(0, 1), xlabel='', ylabel = 'Weighted Recall', yticks=[0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1])\n",
    "axs[2][0].set(ylim=(0, 1), xlabel='', ylabel = 'Precision', yticks=[0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1])\n",
    "axs[2][1].set(ylim=(0, 1), xlabel='', ylabel = 'Weighted Precision', yticks=[0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1])\n",
    "axs[3][0].set(ylim=(0, 1), xlabel='', ylabel = 'Overall Accuracy', yticks=[0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1])\n",
    "axs[3][1].set( xlabel='', ylabel = 'Support')\n",
    "f.tight_layout()\n",
    "\n",
    "f.suptitle(\"Accuracy Assessment Metrics by Date for 4 Training Sets & 2 Image Sources \" ,\n",
    "               fontsize = 'x-large' , \n",
    "               fontweight = 'bold' )\n",
    "# Adjust subplots so that titles don't overlap\n",
    "f.subplots_adjust(top=.95)\n",
    "\n",
    "# # Add a legend and informative axis label\n",
    "# # ax.legend(ncol=2, loc=\"lower right\", frameon=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sporting-english",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_all_df = pd.DataFrame(metrics_all, columns = ['source', 'date_min', 'date_max', 'acc_score', 'precision', 'precision_weighted', 'recall', 'recall_weighted', 'f1', 'f1_weighted', 'support']) \n",
    "metrics_all_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sixth-broadway",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_all_df_wide = pd.melt(metrics_all_df, id_vars=['source'], value_vars=['f1','f1_weighted',\n",
    "                                                        'recall', 'recall_weighted',\n",
    "                                                        'precision', 'precision_weighted',\n",
    "                                                        'acc_score',\n",
    "                                                        ])\n",
    "metrics_all_df_wide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prime-belarus",
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize=(20, 10))\n",
    "sns.barplot(data=metrics_all_df_wide, x=\"variable\", y=\"value\", hue=\"source\", linewidth=0.5, ec='.6')\n",
    "ax.set(xlabel='', ylabel = 'Accuracy Value', yticks=[0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "isolated-indie",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.relplot(data=metrics_bydate_df, x=\"date_min\", y=\"f1\", hue=\"source\", kind=\"line\", height=4, aspect=2)\n",
    "# sns.relplot(data=metrics_bydate_df, x=\"date_min\", y=\"f1_weighted\", hue=\"source\", kind=\"line\", height=4, aspect=2)\n",
    "# sns.relplot(data=metrics_bydate_df, x=\"date_min\", y=\"recall\", hue=\"source\", kind=\"line\", height=4, aspect=2)\n",
    "# sns.relplot(data=metrics_bydate_df, x=\"date_min\", y=\"recall_weighted\", hue=\"source\", kind=\"line\", height=4, aspect=2)\n",
    "# sns.relplot(data=metrics_bydate_df, x=\"date_min\", y=\"precision\", hue=\"source\", kind=\"line\", height=4, aspect=2)\n",
    "# sns.relplot(data=metrics_bydate_df, x=\"date_min\", y=\"precision_weighted\", hue=\"source\", kind=\"line\", height=4, aspect=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "british-jersey",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
